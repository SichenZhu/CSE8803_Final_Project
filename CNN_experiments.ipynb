{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Shaan\\miniconda3\\envs\\pytorc\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.backends.cudnn as cudnn\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NVIDIA GeForce RTX 3070'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()\n",
    "torch.cuda.device_count()\n",
    "torch.cuda.current_device()\n",
    "torch.cuda.device(0)\n",
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "NVIDIA GeForce RTX 3070\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)\n",
    "\n",
    "if device.type == 'cuda':\n",
    "    print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_file_size(path):\n",
    "    return os.stat(path).st_size < 10000000 # 10 MB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir_train = 'D:\\ML for Bio\\\\Binary\\\\train'\n",
    "data_dir_val = 'D:\\ML for Bio\\\\Binary\\\\val'\n",
    "data_dir_test = 'D:\\ML for Bio\\\\Binary\\\\test'\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((600, 600)),\n",
    "    transforms.RandomCrop((400, 400)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "\n",
    "dataset_train = torchvision.datasets.ImageFolder(data_dir_train, transform=transform, target_transform=None, is_valid_file=lambda path: check_file_size(path))\n",
    "dataset_val = torchvision.datasets.ImageFolder(data_dir_val, transform=transform, target_transform=None, is_valid_file=lambda path: check_file_size(path))\n",
    "dataset_test = torchvision.datasets.ImageFolder(data_dir_test, transform=transform, target_transform=None, is_valid_file=lambda path: check_file_size(path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "shuffle = True  \n",
    "num_workers = 16  \n",
    "dataloader_train = torch.utils.data.DataLoader(dataset_train, batch_size=batch_size, shuffle=shuffle, num_workers=num_workers)\n",
    "dataloader_val = torch.utils.data.DataLoader(dataset_val, batch_size=batch_size, shuffle=shuffle, num_workers=num_workers)\n",
    "dataloader_test = torch.utils.data.DataLoader(dataset_test, batch_size=batch_size, shuffle=shuffle, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x2d0a22f0910>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataloader_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "\n",
    "    total_loss = 0.0\n",
    "    num_correct = 0\n",
    "    n = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        progress_bar = tqdm(enumerate(dataloader), total=len(dataloader), desc='1/1', leave=True)\n",
    "\n",
    "        for batch_idx, (images, labels) in progress_bar:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            num_correct += torch.sum(preds == labels)\n",
    "            n += len(labels)\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            #if batch_idx%5 == 0:\n",
    "                #print(\"Loss at batch \" + str(batch_idx) + \": \" + str(loss.item()))\n",
    "            \n",
    "            del images, labels\n",
    "\n",
    "    avg_loss = total_loss / (batch_idx + 1)\n",
    "    accuracy = num_correct / n * 100\n",
    "\n",
    "    print(\"Loss: \" + str(avg_loss))\n",
    "    print(\"Accuracy: \" + str(accuracy))\n",
    "\n",
    "    return avg_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloader, criterion, optimizer, device, epochs, val_dataset, scheduler=None, num_batches=1):\n",
    "    losses = []\n",
    "    accuracies = []\n",
    "    val_losses = []\n",
    "    val_acc = []\n",
    "    best_val = 0\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        model.to(device)\n",
    "        total_loss = 0.0\n",
    "        num_correct = 0\n",
    "        n = 0\n",
    "        progress_bar = tqdm(enumerate(dataloader), total=len(dataloader), desc=f'Epoch {epoch + 1}/{epochs}', leave=True)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        for batch_idx, (images, labels) in progress_bar:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            num_correct += torch.sum(preds == labels)\n",
    "            n += len(labels)\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "\n",
    "            if batch_idx%batch_size == 0 or batch_idx == len(dataloader)-1:\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            del images, labels\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "\n",
    "            \n",
    "        avg_loss_val, accuracy_val = test(model, val_dataset, criterion, device)\n",
    "        val_acc.append(accuracy_val)\n",
    "        val_losses.append(avg_loss_val)\n",
    "\n",
    "        if accuracy_val > best_val:\n",
    "            best_val = accuracy_val\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "\n",
    "        avg_loss = total_loss / (batch_idx + 1)\n",
    "        accuracy = num_correct/n * 100\n",
    "        losses.append(avg_loss)\n",
    "        accuracies.append(accuracy)\n",
    "        print(\"Loss at epoch \" + str(epoch) + \": \" + str(avg_loss))\n",
    "        print(\"Accuracy at epoch \" + str(epoch) + \": \" + str(accuracy))\n",
    "\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, losses, accuracies, val_losses, val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = torchvision.models.efficientnet_b0(weights='DEFAULT')\n",
    "model2 = torch.hub.load('pytorch/vision:v0.10.0', 'resnet18', weights='DEFAULT')\n",
    "model3 = torchvision.models.resnet50(weights = 'DEFAULT')\n",
    "models = [model1, model2, model3]\n",
    "for model in models:\n",
    "    print(\"============================================================\")\n",
    "    print(\"============================TRAIN===========================\")\n",
    "    print(\"============================================================\")\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    epochs = 30\n",
    "    #optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9, weight_decay=0.001)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=0.001)\n",
    "    scheduler = StepLR(optimizer, step_size=5, gamma=0.75)\n",
    "    num_batches = 8\n",
    "    model.to(device)\n",
    "    model, losses, accuracies, val_losses, val_acc = train(model, dataloader_train, criterion, optimizer, device, epochs, dataloader_val, scheduler, num_batches)\n",
    "    print(\"============================================================\")\n",
    "    print(\"============================TEST============================\")\n",
    "    print(\"============================================================\")\n",
    "    avg_loss, accuracy = test(model, dataloader_test, criterion, device)\n",
    "    del model\n",
    "    torch.cuda.empty_cache()        \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
